{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Star Schema "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores the creation of a Star Schema from raw data using Apache Spark.\n",
    "\n",
    "The data used in this notebook is from the Brazilian Basic Education Census, which is available at the [Brazilian government's open data portal](https://download.inep.gov.br/dados_abertos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to create a SparkSession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import psycopg2\n",
    "from datetime import datetime\n",
    "\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "        .appName(\"CensoEscolarStarSchema\")\\\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"4\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming CSV to Parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transformation aims to increase the speed of data loading by using Parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV data\n",
    "data_csv = (\n",
    "    spark\n",
    "    .read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .option(\"delimiter\", \";\")\n",
    "    .option(\"encoding\", \"latin1\")\n",
    "    .load(\"./data/*.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv.write.parquet(\"./data/censo_escolar.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    spark\n",
    "    .read\n",
    "    .format(\"parquet\")\n",
    "    .load(\"./data/censo_escolar.parquet/\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimensions are...\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates the dimensions based on a configuration dict.\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"DIM_NAME\":{\n",
    "        # The fields are the table columns\n",
    "        \"fields\":[\n",
    "            {\n",
    "                \"field\":\"FIELD_1_NAME\", # The column name\n",
    "                \"type\":\"FIELD_1_TYPE\",  # The column type in spark\n",
    "            },\n",
    "            {\n",
    "                \"field\":\"FIELD_2_NAME\",\n",
    "                \"type\":\"FIELD_2_TYPE\",\n",
    "            },\n",
    "            ...\n",
    "        ],\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTEGER_DIMENSIONS = [\n",
    "    \"TP_DEPENDENCIA\",           # The school administration (state, city, private) \n",
    "    \"TP_LOCALIZACAO\",           # The school location (urban rural)\n",
    "    \"IN_AGUA_POTAVEL\",          # has access to drinkable water \n",
    "    \"IN_ENERGIA_INEXISTENTE\",   # has (NOT) access to energy\n",
    "    \"IN_ESGOTO_INEXISTENTE\",    # has (NOT) access to energy\n",
    "    \"IN_BANHEIRO\",              # has restroom\n",
    "    \"IN_BIBLIOTECA\",            # has library\n",
    "    \"IN_REFEITORIO\",            # has canteen \n",
    "    \"IN_COMPUTADOR\",            # has computer\n",
    "    \"IN_INTERNET\",              # has internet\n",
    "    \"IN_EQUIP_NENHUM\"           # no electronic equipment\n",
    "]\n",
    "\n",
    "DIMENSION_TABLES_CONFIG = {\n",
    "    \"DIM_LOCAL\":{\n",
    "        \"fields\": [\n",
    "            {\"field\":\"NO_UF\", \"type\":\"string\",},        # State's name \n",
    "            {\"field\":\"SG_UF\", \"type\":\"string\",},        # State's abbreviation\n",
    "            {\"field\":\"CO_UF\", \"type\":\"string\",},        # State's code\n",
    "            {\"field\":\"NO_MUNICIPIO\", \"type\":\"string\",}, # City's name\n",
    "            {\"field\":\"CO_MUNICIPIO\", \"type\":\"string\",}  # City's code\n",
    "        ]\n",
    "    },\n",
    "}\n",
    "\n",
    "DIMENSION_TABLES_CONFIG.update(\n",
    "    {\n",
    "        \"DIM_\"+dimension.upper():{\n",
    "            \"fields\": [\n",
    "                {\"field\":dimension, \"type\":\"integer\"} \n",
    "            ]\n",
    "        }\n",
    "        for dimension in INTEGER_DIMENSIONS\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dimensions table in Postgres\n",
    "-----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the properties of the Postgres Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTGRES_USER = \"censo\"\n",
    "POSTGRES_PASSWORD = \"123\"\n",
    "POSTGRES_DB = \"censo_escolar\"\n",
    "\n",
    "# Used to connect to the PostgreSQL database server\n",
    "# in spark session\n",
    "POSTGRES_CONFIG = {\n",
    "    \"url\":f\"jdbc:postgresql://localhost:5432/{POSTGRES_DB}\",\n",
    "    \"properties\":{\n",
    "        \"user\":POSTGRES_USER, \n",
    "        \"password\":POSTGRES_PASSWORD,\n",
    "        \"driver\":\"org.postgresql.Driver\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establishing connection to Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\",\n",
    "\n",
    "    dbname=POSTGRES_DB,\n",
    "    user=POSTGRES_USER,\n",
    "    password=POSTGRES_PASSWORD\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create a Dimension table in Postgres using the configuration in DIMENSION_TABLES_CONFIG and adding an id column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates the dimensions\n",
    "Spark will create a table with the name of the dimension and the columns in the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-29 14:50:51.785874] Writing DIM_LOCAL\n",
      "[2024-04-29 14:50:57.143585] Wrote DIM_LOCAL\n",
      "[2024-04-29 14:50:57.345720] Added primary key to DIM_LOCAL\n",
      "[2024-04-29 14:50:57.345720] Done\n",
      "[2024-04-29 14:50:57.345720] Writing DIM_TP_DEPENDENCIA\n",
      "[2024-04-29 14:50:58.498398] Wrote DIM_TP_DEPENDENCIA\n",
      "[2024-04-29 14:50:58.517470] Added primary key to DIM_TP_DEPENDENCIA\n",
      "[2024-04-29 14:50:58.517470] Done\n",
      "[2024-04-29 14:50:58.517470] Writing DIM_TP_LOCALIZACAO\n",
      "[2024-04-29 14:50:59.207641] Wrote DIM_TP_LOCALIZACAO\n",
      "[2024-04-29 14:50:59.234410] Added primary key to DIM_TP_LOCALIZACAO\n",
      "[2024-04-29 14:50:59.234410] Done\n",
      "[2024-04-29 14:50:59.234410] Writing DIM_IN_AGUA_POTAVEL\n",
      "[2024-04-29 14:50:59.886937] Wrote DIM_IN_AGUA_POTAVEL\n",
      "[2024-04-29 14:50:59.915226] Added primary key to DIM_IN_AGUA_POTAVEL\n",
      "[2024-04-29 14:50:59.915336] Done\n",
      "[2024-04-29 14:50:59.915336] Writing DIM_IN_ENERGIA_INEXISTENTE\n",
      "[2024-04-29 14:51:00.560334] Wrote DIM_IN_ENERGIA_INEXISTENTE\n",
      "[2024-04-29 14:51:00.601708] Added primary key to DIM_IN_ENERGIA_INEXISTENTE\n",
      "[2024-04-29 14:51:00.601708] Done\n",
      "[2024-04-29 14:51:00.601708] Writing DIM_IN_ESGOTO_INEXISTENTE\n",
      "[2024-04-29 14:51:01.199131] Wrote DIM_IN_ESGOTO_INEXISTENTE\n",
      "[2024-04-29 14:51:01.208955] Added primary key to DIM_IN_ESGOTO_INEXISTENTE\n",
      "[2024-04-29 14:51:01.208955] Done\n",
      "[2024-04-29 14:51:01.208955] Writing DIM_IN_BANHEIRO\n",
      "[2024-04-29 14:51:01.808760] Wrote DIM_IN_BANHEIRO\n",
      "[2024-04-29 14:51:01.839485] Added primary key to DIM_IN_BANHEIRO\n",
      "[2024-04-29 14:51:01.839485] Done\n",
      "[2024-04-29 14:51:01.839485] Writing DIM_IN_BIBLIOTECA\n",
      "[2024-04-29 14:51:02.488601] Wrote DIM_IN_BIBLIOTECA\n",
      "[2024-04-29 14:51:02.508005] Added primary key to DIM_IN_BIBLIOTECA\n",
      "[2024-04-29 14:51:02.508005] Done\n",
      "[2024-04-29 14:51:02.508005] Writing DIM_IN_REFEITORIO\n",
      "[2024-04-29 14:51:03.105968] Wrote DIM_IN_REFEITORIO\n",
      "[2024-04-29 14:51:03.128878] Added primary key to DIM_IN_REFEITORIO\n",
      "[2024-04-29 14:51:03.129386] Done\n",
      "[2024-04-29 14:51:03.129386] Writing DIM_IN_COMPUTADOR\n",
      "[2024-04-29 14:51:03.696957] Wrote DIM_IN_COMPUTADOR\n",
      "[2024-04-29 14:51:03.721563] Added primary key to DIM_IN_COMPUTADOR\n",
      "[2024-04-29 14:51:03.721563] Done\n",
      "[2024-04-29 14:51:03.721563] Writing DIM_IN_INTERNET\n",
      "[2024-04-29 14:51:04.415022] Wrote DIM_IN_INTERNET\n",
      "[2024-04-29 14:51:04.440931] Added primary key to DIM_IN_INTERNET\n",
      "[2024-04-29 14:51:04.440931] Done\n",
      "[2024-04-29 14:51:04.440931] Writing DIM_IN_EQUIP_NENHUM\n",
      "[2024-04-29 14:51:04.987632] Wrote DIM_IN_EQUIP_NENHUM\n",
      "[2024-04-29 14:51:05.013828] Added primary key to DIM_IN_EQUIP_NENHUM\n",
      "[2024-04-29 14:51:05.015503] Done\n"
     ]
    }
   ],
   "source": [
    "# Write data to Postgres\n",
    "# Using the configuration in DIMENSION_TABLES_CONFIG\n",
    "# With id as the primary key\n",
    "\n",
    "for table_name, table_config in DIMENSION_TABLES_CONFIG.items():\n",
    "    \n",
    "    print(f\"[{datetime.now()}] Writing {table_name}\")\n",
    "    \n",
    "    data\\\n",
    "    .select(\n",
    "        [\n",
    "            F\n",
    "            .col(field[\"field\"])\n",
    "            .cast(field[\"type\"])\n",
    "            .alias(field[\"field\"])\n",
    "            \n",
    "            for field\n",
    "            in table_config[\"fields\"]\n",
    "        ]\n",
    "    )\\\n",
    "    .distinct()\\\n",
    "    .withColumn(\n",
    "        \"id\", F.monotonically_increasing_id()\n",
    "    )\\\n",
    "    .write\\\n",
    "    .jdbc(\n",
    "        **POSTGRES_CONFIG,\n",
    "        table=table_name,\n",
    "        mode=\"overwrite\"\n",
    "    )\n",
    "    \n",
    "    print(f\"[{datetime.now()}] Wrote {table_name}\")\n",
    "    # Define id as the primary key\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\n",
    "        f\"ALTER TABLE {table_name} ADD PRIMARY KEY (id);\"\n",
    "    )\n",
    "    cursor.close()\n",
    "    conn.commit()\n",
    "\n",
    "    print(f\"[{datetime.now()}] Added primary key to {table_name}\")\n",
    "    print(f\"[{datetime.now()}] Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facts table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The definition of the facts table follows a different pattern than the dimensions.\n",
    "\n",
    "The table schema is previously defined to properly define the foreing keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Defining the facts table schema\n",
    "Metrics + Facts + Dimensions (Foreign Keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACT_TABLE_NAME = \"FACT_CENSO_ESCOLAR\"\n",
    "\n",
    "FACT_COLUMNS = [\n",
    "    \"QT_DOC_BAS\",  \t# Number of Teachers in the basic education (TOTAL)\n",
    "    \"QT_DOC_INF\",\t  # Number of Teachers in the basic education (child education)\n",
    "    \"QT_DOC_FUND\",\t# Number of Teachers in the basic education (elementary education)\n",
    "    \"QT_DOC_MED\",\t  # Number of Teachers in the basic education (high school)\n",
    "  \n",
    "    \"QT_MAT_BAS\",\t  # Number of enrollments in the basic education (TOTAL)\n",
    "    \"QT_MAT_INF\",\t  # Number of enrollments in the basic education (child education)\n",
    "    \"QT_MAT_FUND\",\t# Number of enrollments in the basic education (elementary education)\n",
    "    \"QT_MAT_MED\",\t  # Number of enrollments in the basic education (high school)\n",
    "\n",
    "    \"QT_MAT_BAS_ND\",\t      # Number of enrollments in the basic education - Skin color/Race Not Declared\n",
    "    \"QT_MAT_BAS_BRANCA\",\t  # Number of enrollments in the basic education - Skin color/Race Branco\n",
    "    \"QT_MAT_BAS_PRETA\",\t    # Number of enrollments in the basic education - Skin color/Race Preto\n",
    "    \"QT_MAT_BAS_PARDA\",\t    # Number of enrollments in the basic education - Skin color/Race Parda\n",
    "    \"QT_MAT_BAS_AMARELA\",\t  # Number of enrollments in the basic education - Skin color/Race Amarela\n",
    "    \"QT_MAT_BAS_INDIGENA\",\t# Number of enrollments in the basic education - Skin color/Race Indígena\n",
    "    \n",
    "    \"NU_ANO_CENSO\"          # Census' year\n",
    "]\n",
    "\n",
    "FACT_CONFIG = {\n",
    "    fact:{\n",
    "        \"fields\": [\n",
    "            {\"field\":fact, \"type\":\"integer\"}\n",
    "        ]\n",
    "    }\n",
    "    for fact in FACT_COLUMNS\n",
    "}\n",
    "\n",
    "DIMENSION_ID_CONFIG = {\n",
    "    table_name:[\n",
    "        field['field'] \n",
    "        for field \n",
    "        in table_fields['fields']\n",
    "    ]\n",
    "    for table_name, table_fields in DIMENSION_TABLES_CONFIG.items()\n",
    "}\n",
    "\n",
    "FACT_TABLE_ALL_COLUMNS_ORDERED = FACT_COLUMNS + list(map(lambda col:\"ID_\"+col, DIMENSION_ID_CONFIG.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before inserting the data into the facts table, we need to create a function to create the facts table in Postgres\n",
    "\n",
    "The code below creates the facts table in Postgres using the configuration in FACT_TABLES_CONFIG and adding an id column for each dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fact table\n",
    "# Using the configuration in FACT_CONFIG\n",
    "# With id as the primary key\n",
    "\n",
    "# Avoid inserting a backslash into a f-string\n",
    "comma_break_line = \",\\n\\t\\t\\t\"\n",
    "facts_table_sql = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {FACT_TABLE_NAME} (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        { \n",
    "            comma_break_line.join(\n",
    "                [\n",
    "                    f\"{field} INTEGER\" \n",
    "                    for field in FACT_COLUMNS\n",
    "                ]\n",
    "                +[\n",
    "                    f\"ID_{dim_table} BIGINT\"\n",
    "                    for dim_table in DIMENSION_ID_CONFIG.keys()\n",
    "                ]\n",
    "            )\n",
    "        }\n",
    "    );\n",
    "    \n",
    "    -- Adding Foreign Keys\n",
    "    ALTER TABLE {FACT_TABLE_NAME}\n",
    "    {\n",
    "        comma_break_line.join(\n",
    "            [\n",
    "                f\"ADD CONSTRAINT {FACT_TABLE_NAME}_{dim_table}_fk FOREIGN KEY (ID_{dim_table}) REFERENCES {dim_table}(id)\"\n",
    "                for dim_table in DIMENSION_ID_CONFIG.keys()\n",
    "            ]\n",
    "        )\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    CREATE TABLE IF NOT EXISTS FACT_CENSO_ESCOLAR (\n",
      "        id SERIAL PRIMARY KEY,\n",
      "        QT_DOC_BAS INTEGER,\n",
      "\t\t\tQT_DOC_INF INTEGER,\n",
      "\t\t\tQT_DOC_FUND INTEGER,\n",
      "\t\t\tQT_DOC_MED INTEGER,\n",
      "\t\t\tQT_MAT_BAS INTEGER,\n",
      "\t\t\tQT_MAT_INF INTEGER,\n",
      "\t\t\tQT_MAT_FUND INTEGER,\n",
      "\t\t\tQT_MAT_MED INTEGER,\n",
      "\t\t\tQT_MAT_BAS_ND INTEGER,\n",
      "\t\t\tQT_MAT_BAS_BRANCA INTEGER,\n",
      "\t\t\tQT_MAT_BAS_PRETA INTEGER,\n",
      "\t\t\tQT_MAT_BAS_PARDA INTEGER,\n",
      "\t\t\tQT_MAT_BAS_AMARELA INTEGER,\n",
      "\t\t\tQT_MAT_BAS_INDIGENA INTEGER,\n",
      "\t\t\tNU_ANO_CENSO INTEGER,\n",
      "\t\t\tID_DIM_LOCAL BIGINT,\n",
      "\t\t\tID_DIM_TP_DEPENDENCIA BIGINT,\n",
      "\t\t\tID_DIM_TP_LOCALIZACAO BIGINT,\n",
      "\t\t\tID_DIM_IN_AGUA_POTAVEL BIGINT,\n",
      "\t\t\tID_DIM_IN_ENERGIA_INEXISTENTE BIGINT,\n",
      "\t\t\tID_DIM_IN_ESGOTO_INEXISTENTE BIGINT,\n",
      "\t\t\tID_DIM_IN_BANHEIRO BIGINT,\n",
      "\t\t\tID_DIM_IN_BIBLIOTECA BIGINT,\n",
      "\t\t\tID_DIM_IN_REFEITORIO BIGINT,\n",
      "\t\t\tID_DIM_IN_COMPUTADOR BIGINT,\n",
      "\t\t\tID_DIM_IN_INTERNET BIGINT,\n",
      "\t\t\tID_DIM_IN_EQUIP_NENHUM BIGINT\n",
      "    );\n",
      "    \n",
      "    -- Adding Foreign Keys\n",
      "    ALTER TABLE FACT_CENSO_ESCOLAR\n",
      "    ADD CONSTRAINT FACT_CENSO_ESCOLAR_DIM_LOCAL_fk FOREIGN KEY (ID_DIM_LOCAL) REFERENCES DIM_LOCAL(id),\n",
      "\t\t\tADD CONSTRAINT FACT_CENSO_ESCOLAR_DIM_TP_DEPENDENCIA_fk FOREIGN KEY (ID_DIM_TP_DEPENDENCIA) REFERENCES DIM_TP_DEPENDENCIA(id),\n",
      "\t\t\tADD CONSTRAINT FACT_CENSO_ESCOLAR_DIM_TP_LOCALIZACAO_fk FOREIGN KEY (ID_DIM_TP_LOCALIZACAO) REFERENCES DIM_TP_LOCALIZACAO(id),\n",
      "\t\t\tADD CONSTRAINT FACT_CENSO_ESCOLAR_DIM_IN_AGUA_POTAVEL_fk FOREIGN KEY (ID_DIM_IN_AGUA_POTAVEL) REFERENCES DIM_IN_AGUA_POTAVEL(id),\n",
      "\t\t\tADD CONSTRAINT FACT_CENSO_ESCOLAR_DIM_IN_ENERGIA_INEXISTENTE_fk FOREIGN KEY (ID_DIM_IN_ENERGIA_INEXISTENTE) REFERENCES DIM_IN_ENERGIA_INEXISTENTE(id),\n",
      "\t\t\tADD CONSTRAINT FACT_CENSO_ESCOLAR_DIM_IN_ESGOTO_INEXISTENTE_fk FOREIGN KEY (ID_DIM_IN_ESGOTO_INEXISTENTE) REFERENCES DIM_IN_ESGOTO_INEXISTENTE(id),\n",
      "\t\t\tADD CONSTRAINT FACT_CENSO_ESCOLAR_DIM_IN_BANHEIRO_fk FOREIGN KEY (ID_DIM_IN_BANHEIRO) REFERENCES DIM_IN_BANHEIRO(id),\n",
      "\t\t\tADD CONSTRAINT FACT_CENSO_ESCOLAR_DIM_IN_BIBLIOTECA_fk FOREIGN KEY (ID_DIM_IN_BIBLIOTECA) REFERENCES DIM_IN_BIBLIOTECA(id),\n",
      "\t\t\tADD CONSTRAINT FACT_CENSO_ESCOLAR_DIM_IN_REFEITORIO_fk FOREIGN KEY (ID_DIM_IN_REFEITORIO) REFERENCES DIM_IN_REFEITORIO(id),\n",
      "\t\t\tADD CONSTRAINT FACT_CENSO_ESCOLAR_DIM_IN_COMPUTADOR_fk FOREIGN KEY (ID_DIM_IN_COMPUTADOR) REFERENCES DIM_IN_COMPUTADOR(id),\n",
      "\t\t\tADD CONSTRAINT FACT_CENSO_ESCOLAR_DIM_IN_INTERNET_fk FOREIGN KEY (ID_DIM_IN_INTERNET) REFERENCES DIM_IN_INTERNET(id),\n",
      "\t\t\tADD CONSTRAINT FACT_CENSO_ESCOLAR_DIM_IN_EQUIP_NENHUM_fk FOREIGN KEY (ID_DIM_IN_EQUIP_NENHUM) REFERENCES DIM_IN_EQUIP_NENHUM(id)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(facts_table_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing the function to create the facts table in Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-29 14:55:36.635973] Creating facts table\n",
      "[2024-04-29 14:55:36.842779] Created facts table\n",
      "[2024-04-29 14:55:36.843736] Done\n"
     ]
    }
   ],
   "source": [
    "print(f\"[{datetime.now()}] Creating facts table\")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "try:\n",
    "    cursor.execute(facts_table_sql)\n",
    "    cursor.close()\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    conn.rollback()\n",
    "    cursor.close()\n",
    "else:\n",
    "    print(f\"[{datetime.now()}] Created facts table\")\n",
    "    print(f\"[{datetime.now()}] Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_data = data\\\n",
    "    .select(\n",
    "        [\n",
    "            *chain(\n",
    "                *DIMENSION_ID_CONFIG.values(), \n",
    "                FACT_CONFIG.keys()\n",
    "            )\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the ids for each dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the id of the dimensions\n",
    "\n",
    "for table_name, table_fields in DIMENSION_ID_CONFIG.items():\n",
    "    \n",
    "    # Read the dimension data from Postgres\n",
    "    dim_table = spark.read\\\n",
    "        .jdbc(\n",
    "            **POSTGRES_CONFIG,\n",
    "            table=table_name,\n",
    "        )\\\n",
    "        .withColumnRenamed(\"id\", f\"ID_{table_name}\")\n",
    "    \n",
    "    # Join the dimension data with the fact data\n",
    "    facts_data = facts_data\\\n",
    "        .join(\n",
    "            dim_table,\n",
    "            on=table_fields,\n",
    "            how=\"left\"\n",
    "        )\\\n",
    "        .drop(*table_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving data to Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the columns to match the fact table on postgres\n",
    "# and save the data\n",
    "facts_data\\\n",
    "    .select(*FACT_TABLE_ALL_COLUMNS_ORDERED)\\\n",
    "    .write\\\n",
    "    .jdbc(\n",
    "        **POSTGRES_CONFIG,\n",
    "        table=FACT_TABLE_NAME,\n",
    "        mode=\"append\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLAP Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can execute queries in Spark SQL, we need to make view for each tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_data = spark.read.jdbc(**POSTGRES_CONFIG, table='FACT_CENSO_ESCOLAR')\n",
    "# Register the fact table as a temporary view\n",
    "facts_data.createOrReplaceTempView('FACT_CENSO_ESCOLAR')\n",
    "\n",
    "# Loop through dimension tables\n",
    "for table_name, table_fields in DIMENSION_ID_CONFIG.items():\n",
    "    \n",
    "    # Read the dimension data from Postgres\n",
    "    dim_table = spark.read.jdbc(**POSTGRES_CONFIG, table=table_name)\\\n",
    "                      .withColumnRenamed(\"id\", f\"ID_{table_name}\")\n",
    "    \n",
    "    # Register each dimension table as a temporary view\n",
    "    dim_table.createOrReplaceTempView(table_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roll-Up & Drill-Down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misal awalnya adalah data jumlah pengajar berdasarkan State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+\n",
      "|              NO_UF|TOTAL_TEACHERS|\n",
      "+-------------------+--------------+\n",
      "|               Acre|        154260|\n",
      "|            Alagoas|        496007|\n",
      "|              Amapá|        140811|\n",
      "|           Amazonas|        667797|\n",
      "|              Bahia|       2201321|\n",
      "|              Ceará|       1374453|\n",
      "|   Distrito Federal|        388278|\n",
      "|     Espírito Santo|        679657|\n",
      "|              Goiás|        857545|\n",
      "|           Maranhão|       1437367|\n",
      "|        Mato Grosso|        543119|\n",
      "| Mato Grosso do Sul|        493332|\n",
      "|       Minas Gerais|       3327083|\n",
      "|             Paraná|       2127370|\n",
      "|            Paraíba|        700280|\n",
      "|               Pará|       1305632|\n",
      "|         Pernambuco|       1284867|\n",
      "|              Piauí|        715725|\n",
      "|Rio Grande do Norte|        519593|\n",
      "|  Rio Grande do Sul|       1820483|\n",
      "+-------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\"\"\"\n",
    "    SELECT NO_UF, SUM(QT_DOC_BAS) AS TOTAL_TEACHERS\n",
    "    FROM FACT_CENSO_ESCOLAR\n",
    "    JOIN DIM_LOCAL ON FACT_CENSO_ESCOLAR.ID_DIM_LOCAL = DIM_LOCAL.ID_DIM_LOCAL\n",
    "    GROUP BY NO_UF\n",
    "    ORDER BY NO_UF;\n",
    "\n",
    "\"\"\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jika kita Lakukan Drill-Down, maka kita ingin melihat berdasarkan City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------+\n",
      "|NO_UF|        NO_MUNICIPIO|TOTAL_TEACHERS|\n",
      "+-----+--------------------+--------------+\n",
      "| Acre|          Acrelândia|          2113|\n",
      "| Acre|        Assis Brasil|          2291|\n",
      "| Acre|           Brasiléia|          3986|\n",
      "| Acre|              Bujari|          2394|\n",
      "| Acre|            Capixaba|          1761|\n",
      "| Acre|     Cruzeiro do Sul|         19748|\n",
      "| Acre|      Epitaciolândia|          2480|\n",
      "| Acre|               Feijó|          7902|\n",
      "| Acre|              Jordão|          2590|\n",
      "| Acre|       Manoel Urbano|          1710|\n",
      "| Acre|Marechal Thaumaturgo|          5027|\n",
      "| Acre|         Mâncio Lima|          4819|\n",
      "| Acre|   Plácido de Castro|          3204|\n",
      "| Acre|          Porto Acre|          3230|\n",
      "| Acre|        Porto Walter|          2862|\n",
      "| Acre|          Rio Branco|         55949|\n",
      "| Acre|     Rodrigues Alves|          5423|\n",
      "| Acre| Santa Rosa do Purus|          1951|\n",
      "| Acre|      Sena Madureira|          7577|\n",
      "| Acre|    Senador Guiomard|          4346|\n",
      "+-----+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\"\"\"\n",
    "    SELECT NO_UF, NO_MUNICIPIO, SUM(QT_DOC_BAS) AS TOTAL_TEACHERS\n",
    "    FROM FACT_CENSO_ESCOLAR\n",
    "    JOIN DIM_LOCAL ON FACT_CENSO_ESCOLAR.ID_DIM_LOCAL = DIM_LOCAL.ID_DIM_LOCAL\n",
    "    GROUP BY NO_UF, NO_MUNICIPIO\n",
    "    ORDER BY NO_UF, NO_MUNICIPIO;\n",
    "\n",
    "\"\"\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebaliknya jika merubah dari berdasarkan City menjadi berdasarkan State, itu adalah Roll-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice & Dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misal awalnya menampilkan state, dan jumlah pengajar untuk tiap city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------------+\n",
      "|       NO_MUNICIPIO|              NO_UF|TOTAL_TEACHERS|\n",
      "+-------------------+-------------------+--------------+\n",
      "|    Abadia de Goiás|              Goiás|          1255|\n",
      "|Abadia dos Dourados|       Minas Gerais|           990|\n",
      "|          Abadiânia|              Goiás|          1881|\n",
      "|         Abaetetuba|               Pará|         29058|\n",
      "|             Abaeté|       Minas Gerais|          3102|\n",
      "|            Abaiara|              Ceará|          1795|\n",
      "|              Abaré|              Bahia|          3344|\n",
      "|             Abatiá|             Paraná|          1573|\n",
      "|             Abaíra|              Bahia|          1336|\n",
      "|      Abdon Batista|     Santa Catarina|           641|\n",
      "|    Abel Figueiredo|               Pará|           954|\n",
      "|       Abelardo Luz|     Santa Catarina|          3240|\n",
      "|         Abre Campo|       Minas Gerais|          2419|\n",
      "|       Abreu e Lima|         Pernambuco|         10593|\n",
      "|        Abreulândia|          Tocantins|           552|\n",
      "|            Acaiaca|       Minas Gerais|          1080|\n",
      "|          Acajutiba|              Bahia|          2493|\n",
      "|            Acarape|              Ceará|          1857|\n",
      "|             Acaraú|              Ceará|         10184|\n",
      "|              Acari|Rio Grande do Norte|          1382|\n",
      "+-------------------+-------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\"\"\"\n",
    "    SELECT NO_MUNICIPIO, NO_UF, SUM(QT_DOC_BAS) AS TOTAL_TEACHERS\n",
    "    FROM FACT_CENSO_ESCOLAR\n",
    "    JOIN DIM_LOCAL ON FACT_CENSO_ESCOLAR.ID_DIM_LOCAL = DIM_LOCAL.ID_DIM_LOCAL\n",
    "    GROUP BY NO_MUNICIPIO, NO_UF\n",
    "    ORDER BY NO_MUNICIPIO;\n",
    "\n",
    "\"\"\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kemudian dengan melakukan slice, kita hanya ingin tunjukkan yang berada di State Bahia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+--------------+\n",
      "|     NO_MUNICIPIO|NO_UF|TOTAL_TEACHERS|\n",
      "+-----------------+-----+--------------+\n",
      "|            Abaré|Bahia|          3344|\n",
      "|           Abaíra|Bahia|          1336|\n",
      "|        Acajutiba|Bahia|          2493|\n",
      "|         Adustina|Bahia|          2649|\n",
      "|          Aiquara|Bahia|           907|\n",
      "|       Alagoinhas|Bahia|         20008|\n",
      "|         Alcobaça|Bahia|          4099|\n",
      "|         Almadina|Bahia|          1077|\n",
      "|         Amargosa|Bahia|          5492|\n",
      "| Amélia Rodrigues|Bahia|          4152|\n",
      "|  América Dourada|Bahia|          2421|\n",
      "|            Anagé|Bahia|          3271|\n",
      "|          Andaraí|Bahia|          2811|\n",
      "|        Andorinha|Bahia|          2750|\n",
      "|          Angical|Bahia|          2703|\n",
      "|          Anguera|Bahia|          1914|\n",
      "|            Antas|Bahia|          2321|\n",
      "|  Antônio Cardoso|Bahia|          1893|\n",
      "|Antônio Gonçalves|Bahia|          2587|\n",
      "|            Aporá|Bahia|          3576|\n",
      "+-----------------+-----+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\"\"\"\n",
    "    SELECT NO_MUNICIPIO, NO_UF, SUM(QT_DOC_BAS) AS TOTAL_TEACHERS\n",
    "    FROM FACT_CENSO_ESCOLAR\n",
    "    JOIN DIM_LOCAL ON FACT_CENSO_ESCOLAR.ID_DIM_LOCAL = DIM_LOCAL.ID_DIM_LOCAL\n",
    "    WHERE DIM_LOCAL.NO_UF = 'Bahia'\n",
    "    GROUP BY NO_MUNICIPIO, NO_UF\n",
    "    ORDER BY NO_MUNICIPIO;\n",
    "\n",
    "\"\"\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jika kita melakukan dice, kita bisa kecilkan lagi dimensi nya menjadi hanya yang City Antas dan State Bahia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+--------------+\n",
      "|NO_MUNICIPIO|NO_UF|TOTAL_TEACHERS|\n",
      "+------------+-----+--------------+\n",
      "|       Antas|Bahia|          2321|\n",
      "+------------+-----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\"\"\"\n",
    "    SELECT NO_MUNICIPIO, NO_UF, SUM(QT_DOC_BAS) AS TOTAL_TEACHERS\n",
    "    FROM FACT_CENSO_ESCOLAR\n",
    "    JOIN DIM_LOCAL ON FACT_CENSO_ESCOLAR.ID_DIM_LOCAL = DIM_LOCAL.ID_DIM_LOCAL\n",
    "    WHERE DIM_LOCAL.NO_UF = 'Bahia' AND DIM_LOCAL.NO_MUNICIPIO = 'Antas'\n",
    "    GROUP BY NO_MUNICIPIO, NO_UF\n",
    "    ORDER BY NO_MUNICIPIO;\n",
    "\n",
    "\"\"\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/explaining-technical-stuff-in-a-non-techincal-way-apache-spark-274d6c9f70e9\n",
    "\n",
    "https://towardsdatascience.com/adding-sequential-ids-to-a-spark-dataframe-fa0df5566ff6\n",
    "\n",
    "https://sparkbyexamples.com/pyspark/pyspark-read-and-write-parquet-file/\n",
    "\n",
    "https://www.psycopg.org/docs/usage.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
